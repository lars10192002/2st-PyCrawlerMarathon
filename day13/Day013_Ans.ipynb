{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PTT 網路爬蟲實作練習\n",
    "\n",
    "\n",
    "* 能夠利用 Request + BeatifulSour 撰寫爬蟲，並存放到合適的資料結構\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 作業目標\n",
    "\n",
    "根據範例 ，完成以下問題：\n",
    "\n",
    "* ① 印出最新文章的「作者」「標題」「時間」\n",
    "* ② 印出第一頁所有文章的「作者」「標題」「時間」\n",
    "* ③ 試著爬爬看其他版的文章\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/Stock/index.html'\n",
    "r = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html5lib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ② 印出第一頁所有文章的「作者」「標題」「時間」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 方法一：只從首頁\n",
    "for d in soup.find_all(class_=\"r-ent\"):\n",
    "    print('標題： ', d.find(class_='title').text.replace('\\t', '').replace('\\n', ''))\n",
    "    print('作者： ', d.find(class_='author').text.replace('\\t', '').replace('\\n', ''))\n",
    "    print('時間： ', d.find(class_='date').text.replace('\\t', '').replace('\\n', ''))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "標題：  [請益] 買晶圓雙雄可以嗎？\n",
      "作者： aaasssddd (希望相隨)\n",
      "時間： Thu Dec 12 09:34:29 2019\n",
      "標題：  (本文已被刪除) [greattower]\n",
      "標題：  Re: [請益] 買晶圓雙雄可以嗎？\n",
      "作者： gametheory (正直和善良會回來)\n",
      "時間： Thu Dec 12 10:29:14 2019\n",
      "標題：  [請益] 幫媽媽存的GG該買回來嗎\n",
      "作者： c0854206 (雙層起司豬排)\n",
      "時間： Thu Dec 12 10:32:41 2019\n",
      "標題：  [公告] 精華區導覽Q&A\n",
      "作者： IanLi (IanLi)\n",
      "時間： Sun Jan 25 23:18:20 2015\n",
      "標題：  [公告] Stock 板規V2.6             (2019/06/20)\n",
      "標題：  [閒聊] 2019/12/12 盤中閒聊\n",
      "作者： justforsing (雯晴啦不是晴雯)\n",
      "時間： Thu Dec 12 08:30:02 2019\n"
     ]
    }
   ],
   "source": [
    "# 方法二：進入內頁抓\n",
    "for d in soup.find_all(class_=\"title\"):\n",
    "    try:\n",
    "        print('標題： ', d.text.replace('\\t', '').replace('\\n', ''))\n",
    "        r = BeautifulSoup(requests.get('https://www.ptt.cc'+d.find('a')['href']).text, \"html5lib\")\n",
    "        print('作者： ' + r.find(class_='article-meta-value').text)\n",
    "        print('時間： ' + r.find_all(class_='article-meta-value')[-1].text)\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ① 印出最新文章的「作者」「標題」「時間」"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'標題': '[請益] 幫媽媽存的GG該買回來嗎',\n",
       " '作者': 'c0854206 (雙層起司豬排)',\n",
       " '時間': 'Thu Dec 12 10:32:41 2019'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 因為原始的資料難以判斷「新/舊」，因此我們必須進入內頁抓取詳細的時間，最終存成 List of Dict 的形式再自行排序。\n",
    "\n",
    "posts = []\n",
    "\n",
    "for d in soup.find_all(class_=\"title\"):\n",
    "    try:\n",
    "        post = {}\n",
    "        post['標題'] = d.text.replace('\\t', '').replace('\\n', '')\n",
    "        \n",
    "        r = BeautifulSoup(requests.get('https://www.ptt.cc'+d.find('a')['href']).text, \"html5lib\")\n",
    "        post['作者'] = r.find(class_='article-meta-value').text\n",
    "        post['時間'] = r.find_all(class_='article-meta-value')[-1].text\n",
    "        \n",
    "        posts.append(post)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "posts = sorted(posts, key= lambda x: x['時間'])\n",
    "# 補充：List of Dict 的排序方法\n",
    "# https://stackoverflow.com/questions/72899/how-do-i-sort-a-list-of-dictionaries-by-a-value-of-the-dictionary\n",
    "posts[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ③ 試著爬爬看其他版的文章"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'標題': '[情報] 蝦皮雙12家用品&衛生紙0.063/抽',\n",
       " '作者': 'Drummer14 (血族女妖)',\n",
       " '時間': 'Thu Dec 12 11:05:25 2019'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 改成 Lifeismoney 版，抓出最新一筆的文章\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/Lifeismoney/index.html'\n",
    "r = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "\n",
    "posts = []\n",
    "\n",
    "for d in soup.find_all(class_=\"title\"):\n",
    "    try:\n",
    "        post = {}\n",
    "        post['標題'] = d.text.replace('\\t', '').replace('\\n', '')\n",
    "        \n",
    "        r = BeautifulSoup(requests.get('https://www.ptt.cc'+d.find('a')['href']).text, \"html5lib\")\n",
    "        post['作者'] = r.find(class_='article-meta-value').text\n",
    "        post['時間'] = r.find_all(class_='article-meta-value')[-1].text\n",
    "        \n",
    "        posts.append(post)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "posts = sorted(posts, key= lambda x: x['時間'])\n",
    "posts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-088bdb8a195e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0mposts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'時間'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mposts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 改成 Gossiping 版，發生錯誤，因為八卦版會跳轉到一個「十八歲的同意驗證頁面」導致錯誤。\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/Gossiping/index.html'\n",
    "r = requests.get(url)\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "\n",
    "posts = []\n",
    "\n",
    "for d in soup.find_all(class_=\"title\"):\n",
    "    try:\n",
    "        post = {}\n",
    "        post['標題'] = d.text.replace('\\t', '').replace('\\n', '')\n",
    "        \n",
    "        r = BeautifulSoup(requests.get('https://www.ptt.cc'+d.find('a')['href']).text, \"html5lib\")\n",
    "        post['作者'] = r.find(class_='article-meta-value').text\n",
    "        post['時間'] = r.find_all(class_='article-meta-value')[-1].text\n",
    "        \n",
    "        posts.append(post)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "posts = sorted(posts, key= lambda x: x['時間'])\n",
    "posts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'標題': '[公告] 宣導禁止回文政問',\n",
       " '作者': 'arsonlolita (板主)',\n",
       " '時間': 'Wed Nov 20 09:14:42 2019'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 改成 Gossiping 版，發生錯誤，因為八卦版會跳轉到一個「十八歲的同意驗證頁面」導致錯誤。\n",
    "# 參考圖片下載時的解法，加上 cookies 繞過驗證（後面課程會再進行補充）\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/Gossiping/index.html'\n",
    "r = requests.get(url, cookies={'over18': '1'})\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "\n",
    "posts = []\n",
    "\n",
    "for d in soup.find_all(class_=\"title\"):\n",
    "    try:\n",
    "        post = {}\n",
    "        post['標題'] = d.text.replace('\\t', '').replace('\\n', '')\n",
    "        \n",
    "        r = BeautifulSoup(requests.get('https://www.ptt.cc'+d.find('a')['href'], cookies={'over18': '1'}).text, \"html5lib\")\n",
    "        post['作者'] = r.find(class_='article-meta-value').text\n",
    "        post['時間'] = r.find_all(class_='article-meta-value')[-1].text\n",
    "        \n",
    "        posts.append(post)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "posts = sorted(posts, key= lambda x: x['時間'])\n",
    "posts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'標題': '[新聞] 共青團捧網紅 網友：她怎麼上YouTube的',\n",
       " '作者': 'KahoJyumonji (Kahojyumonji)',\n",
       " '時間': datetime.datetime(2019, 12, 12, 11, 16, 52)}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我們發現這個時間好像不是正確的，原因是我們前面存到的時間，其實不是正確的格式\n",
    "\n",
    "# 改成 Gossiping 版，發生錯誤，因為八卦版會跳轉到一個「十八歲的同意驗證頁面」導致錯誤。\n",
    "# 參考圖片下載時的解法，加上 cookies 繞過驗證（後面課程會再進行補充）\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.ptt.cc/bbs/Gossiping/index.html'\n",
    "r = requests.get(url, cookies={'over18': '1'})\n",
    "\n",
    "soup = BeautifulSoup(r.text, \"html5lib\")\n",
    "\n",
    "posts = []\n",
    "\n",
    "for d in soup.find_all(class_=\"title\"):\n",
    "    try:\n",
    "        post = {}\n",
    "        post['標題'] = d.text.replace('\\t', '').replace('\\n', '')\n",
    "        \n",
    "        r = BeautifulSoup(requests.get('https://www.ptt.cc'+d.find('a')['href'], cookies={'over18': '1'}).text, \"html5lib\")\n",
    "        post['作者'] = r.find(class_='article-meta-value').text\n",
    "        post['時間'] = r.find_all(class_='article-meta-value')[-1].text\n",
    "        post['時間'] = datetime.strptime(post['時間'], \"%a %b %d %H:%M:%S %Y\")\n",
    "        # 時間轉換：https://stackoverflow.com/questions/10256093/how-to-convert-ctime-to-datetime-in-python\n",
    "        \n",
    "        posts.append(post)\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "posts = sorted(posts, key= lambda x: x['時間'])\n",
    "posts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
